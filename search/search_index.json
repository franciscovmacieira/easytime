{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to \"Easy to Explain: Time-Series Features\"","text":"<p>This Python library offers diverse solution for advanced time-series analysis. This library is built to empower developers and data scientists by simplifying complex time-series tasks.</p>"},{"location":"index.html#what-it-does","title":"What It Does","text":"<p><code>easyts</code> equips you with a robust set of features to master your time-series data:</p> <ul> <li> <p>\ud83d\udcc8 Trend Analysis: Quantify the direction, strength, and stability of the trend in your time-series.</p> </li> <li> <p>\u26a1\ufe0f Noise &amp; Volatility Modeling: Characterize the randomness, complexity, and predictability of your time-series.</p> </li> <li> <p>\ud83c\udf0a Seasonality Detection: Identify and measure the strength of recurring, cyclical patterns.</p> </li> <li> <p>\ud83e\udd16 Model Selection: Extract key statistical properties to guide your choice of forecasting models.</p> </li> <li> <p>\ud83d\udd0d Clustering &amp; Classification: Generate unique fingerprints for your time-series to use in machine learning tasks.</p> </li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"<p>Get started in seconds.</p> <pre><code>pip install easyts \n</code></pre>"},{"location":"index.html#context","title":"Context","text":"<p>This library was developed as the focus of a research initiative by Francisco Macieira, an undergraduate student of Artificial Intelligence and Data Science at FCUP. The project was supervised by Professor Mois\u00e9s Santos, affiliated with both FCUP and FEUP.</p>"},{"location":"api_reference.html","title":"API Reference","text":""},{"location":"api_reference.html#introduction","title":"Introduction","text":"<p>This document provides a detailed reference for the <code>easyts</code> library API. It covers installation, basic usage, and a complete guide to all available functions for time-series feature extraction.</p>"},{"location":"api_reference.html#installation","title":"Installation","text":"<p>Install the library from PyPI using pip:</p> <pre><code>pip install easyts\n</code></pre>"},{"location":"api_reference.html#basic-usage","title":"Basic Usage","text":"<p>To get started, import the library and a numerical package like NumPy. Then you can call any feature-extraction function with your time-series data.</p> <pre><code>import easyts\nimport numpy as np\n\n# Create a sample time-series\nmy_series = np.array([1, 2, 4, 8, 12, 18, 25, 33, 45, 58])\n\n# Calculate a feature\nslope = easyts.linear_regression_slope(my_series)\n\nprint(f\"The slope of the series is: {slope}\")\n</code></pre>"},{"location":"api_reference.html#exceptions","title":"Exceptions","text":"<p>The library uses standard Python exceptions to report errors. The most common are: * <code>ValueError</code>: Raised when a function receives an argument of the correct type but an inappropriate value (e.g., a time-series that is too short for a given calculation). * <code>TypeError</code>: Raised when a function receives an argument of the wrong type (e.g., a list where a NumPy array is expected).</p>"},{"location":"api_reference.html#functions-reference","title":"Functions Reference","text":""},{"location":"api_reference.html#trend-analysis","title":"Trend Analysis","text":"<p>Functions to quantify the direction, strength, and stability of a trend.</p>"},{"location":"api_reference.html#trend_strengthseries-period1-seasonal7-robustfalse","title":"<code>trend_strength(series, period=1, seasonal=7, robust=False)</code>","text":"<p>Uses STL decomposition to measure how dominant the trend component is compared to the remainder. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data.     - <code>period</code> (int, optional): The seasonal period of the series. Defaults to 1.     - <code>seasonal</code> (int, optional): The length of the seasonal smoother. Must be odd. Defaults to 7.     - <code>robust</code> (bool, optional): If <code>True</code>, the decomposition is more resistant to outliers. Defaults to <code>False</code>. - Returns: (<code>float</code>) A value between 0.0 (no trend) and 1.0 (strongest trend). - Example: <pre><code>strength = easyts.trend_strength(my_series)\n</code></pre></p>"},{"location":"api_reference.html#trend_changesseries-modell2-min_size2-jump5-paramsnone-custom_costnone","title":"<code>trend_changes(series, model=\"l2\", min_size=2, jump=5, params=None, custom_cost=None)</code>","text":"<p>Detects the number of abrupt change points in a series using the Pelt algorithm. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data.     - <code>model</code> (str, optional): The cost model for the change point detection. Defaults to \"l2\".     - <code>jump</code> (int, optional): Subsample window for considering change points. Defaults to 2.     - <code>params</code> (dict or None, optional): Additional parameters dictionary for the cost 'model'. Defaults to None.     - <code>custom_cost</code> (BaseCost or None, optional): Custom cost function (overrides 'model'). Defaults to None. - Returns: (<code>int</code>) The number of detected trend change points. - Example: <pre><code>changes = easyts.trend_changes(my_series)\n</code></pre></p>"},{"location":"api_reference.html#linear_regression_slopeseries","title":"<code>linear_regression_slope(series)</code>","text":"<p>Fits a linear regression to the series and returns its slope. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The slope of the fitted line, indicating direction and steepness. - Example: <pre><code>slope = easyts.linear_regression_slope(my_series)\n</code></pre></p>"},{"location":"api_reference.html#linear_regression_r2series","title":"<code>linear_regression_r2(series)</code>","text":"<p>Fits a linear regression and returns its R-squared value, indicating goodness of fit. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The R-squared value, between 0.0 and 1.0. - Example: <pre><code>r2_score = easyts.linear_regression_r2(my_series)\n</code></pre></p>"},{"location":"api_reference.html#noisevolatility","title":"Noise/Volatility","text":"<p>Functions to characterize the randomness, complexity, and predictability of a series.</p>"},{"location":"api_reference.html#forecastabilityseries-sf-methodwelch-npersegnone-normalizefalse","title":"<code>forecastability(series, sf, method=\"welch\", nperseg=None, normalize=False)</code>","text":"<p>Calculates the spectral entropy, a measure of the series' forecastability. Lower entropy means higher forecastability. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data.     - <code>sf</code> (float, mandatory): The sampling frequency of the series. Defaults to 1.0.     - <code>nperseg</code> (int or None, optional): Segment length for welch method. If None, default based on data length.     - <code>normalize</code> (bool, optional): Normalize output to [0, 1]. Defaults to False. - Returns: (<code>float</code>) The spectral entropy of the series. - Example: <pre><code>entropy = easyts.forecastability(my_series, sf=1.0)\n</code></pre></p>"},{"location":"api_reference.html#fluctuationseries","title":"<code>fluctuation(series)</code>","text":"<p>Measures variability between consecutive data points to quantify local smoothness. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The fluctuation value. - Example: <pre><code>fluc = easyts.fluctuation(my_series)\n</code></pre></p>"},{"location":"api_reference.html#window_fluctuationseries","title":"<code>window_fluctuation(series)</code>","text":"<p>Assesses self-similar fluctuations across different time scales. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The window fluctuation value. - Example: <pre><code>win_fluc = easyts.window_fluctuation(my_series)\n</code></pre></p>"},{"location":"api_reference.html#seasonality-detection","title":"Seasonality Detection","text":"<p>Functions to identify and measure the strength of recurring patterns.</p>"},{"location":"api_reference.html#seasonal_strengthseries-period1-seasonal7-robustfalse","title":"<code>seasonal_strength(series, period=1, seasonal=7, robust=False)</code>","text":"<p>Uses STL decomposition to measure how dominant the seasonal component is. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data.     - <code>period</code> (int, optional): The seasonal period. Defaults to 1.     - <code>seasonal</code> (int, optional): Length of the seasonal smoother. Must be odd. Defaults to 7.     - <code>robust</code> (bool, optional): If <code>True</code>, the decomposition is more resistant to outliers. Defaults to <code>False</code>. - Returns: (<code>float</code>) A value between 0.0 (no seasonality) and 1.0 (strongest seasonality). - Example: <pre><code>season_str = easyts.seasonal_strength(my_series)\n</code></pre></p>"},{"location":"api_reference.html#ac_relevanceseries","title":"<code>ac_relevance(series)</code>","text":"<p>Finds the first zero-crossing of the autocorrelation function, indicating how quickly the series \"memory\" decays. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The lag of the first autocorrelation zero-crossing. - Example: <pre><code>relevance = easyts.ac_relevance(my_series)\n</code></pre></p>"},{"location":"api_reference.html#model-selection","title":"Model Selection","text":"<p>Functions to extract statistical properties to guide forecasting model choice.</p>"},{"location":"api_reference.html#st_variationseries","title":"<code>st_variation(series)</code>","text":"<p>Measures the amount of high-frequency, short-term variation in the data. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The short-term variation value. - Example: <pre><code>variation = easyts.st_variation(my_series)\n</code></pre></p>"},{"location":"api_reference.html#diff_seriesseries","title":"<code>diff_series(series)</code>","text":"<p>Calculates the sum of squared autocorrelations for the first-differenced series. Useful for ARIMA model parameterization. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The autocorrelation feature of the differenced series. - Example: <pre><code>diff_acf = easyts.diff_series(my_series)\n</code></pre></p>"},{"location":"api_reference.html#complexityseries","title":"<code>complexity(series)</code>","text":"<p>Calculates the Complexity Estimate, a measure of how \"wiggly\" or complex a series is. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The complexity estimate value. - Example: <pre><code>comp = easyts.complexity(my_series)\n</code></pre></p>"},{"location":"api_reference.html#clustering-and-classification","title":"Clustering and Classification","text":"<p>Functions to generate unique fingerprints for time-series to use in machine learning tasks.</p>"},{"location":"api_reference.html#rec_concentrationseries","title":"<code>rec_concentration(series)</code>","text":"<p>Creates a histogram to find where the series values are most concentrated. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data. - Returns: (<code>float</code>) The mode of the 10-bin histogram of the series. - Example: <pre><code>concentration = easyts.rec_concentration(my_series)\n</code></pre></p>"},{"location":"api_reference.html#centroidseries-fs1","title":"<code>centroid(series, fs=1)</code>","text":"<p>Computes the spectral centroid, or the \"center of mass\" of the series' frequency spectrum. - Parameters:     - <code>series</code> (numpy.ndarray): The 1D time-series data.     - <code>fs</code> (int, mandatory): The sampling frequency. - Returns: (<code>float</code>) The spectral centroid value. - Example: <pre><code>spec_centroid = easyts.centroid(my_series, fs=1)\n</code></pre></p>"},{"location":"api_reference.html#information","title":"Information","text":""},{"location":"api_reference.html#info","title":"<code>info()</code>","text":"<p>A static method that prints a brief description of all available features to the console. - Parameters: None. - Returns: None. Prints to standard output. - Example:     ```python     easyts.info()</p>"},{"location":"changelog.html","title":"Changelog","text":""},{"location":"changelog.html#v010-20062025","title":"v0.1.0 (20/06/2025)","text":"<ul> <li>First release of <code>Easy to Explain: Time-Series Features</code>!</li> </ul>"},{"location":"contributing.html","title":"Types of Contributions","text":""},{"location":"contributing.html#report-bugs","title":"Report Bugs","text":"<p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing.html#write-documentation","title":"Write Documentation","text":"<p>You can never have enough documentation! Please feel free to contribute to any part of the documentation, such as the official website or the GitHub repository.</p>"},{"location":"contributing.html#submit-feedback","title":"Submit Feedback","text":"<p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions     are welcome :)</li> </ul>"},{"location":"contributing.html#get-started","title":"Get Started!","text":"<p>Ready to contribute to <code>easyts</code>? Here's how to set up your local development environment.</p>"},{"location":"contributing.html#1-fork-and-clone-the-repository","title":"1. Fork and Clone the Repository","text":"<p>First, navigate to the <code>easyts</code> GitHub repository and click the \"Fork\" button in the top-right corner. This creates your own copy of the project.</p> <p>Next, clone your forked repository to your local machine. Replace <code>[Your-GitHub-Username]</code> with your actual username.</p> <pre><code>git clone [https://github.com/](https://github.com/)[Your-GitHub-Username]/easyts.git\ncd easyts\n</code></pre>"},{"location":"contributing.html#2-create-and-activate-a-virtual-environment","title":"2. Create and Activate a Virtual Environment","text":"<p>It's highly recommended to work in a virtual environment. This keeps your project's dependencies isolated.</p> <pre><code># Create the virtual environment\npython -m venv venv\n\n# Activate it (macOS/Linux)\nsource venv/bin/activate\n\n# Or activate it (Windows)\nvenv\\Scripts\\activate\n</code></pre>"},{"location":"contributing.html#3-install-dependencies-in-editable-mode","title":"3. Install Dependencies in Editable Mode","text":"<p>Install the required packages from the <code>requirements.txt</code> file. Then, install <code>easyts</code> itself in \"editable\" mode (<code>-e .</code>) so your code changes take effect immediately.</p> <p><pre><code># Install dependencies\npip install -r requirements.txt\n\n# Install the project in editable mode\npip install -e .\n</code></pre> (Note: If you don't have a <code>requirements.txt</code> file, you can create one in your project with <code>pip freeze &gt; requirements.txt</code> after installing all necessary packages.)</p>"},{"location":"contributing.html#4-create-a-new-branch","title":"4. Create a New Branch","text":"<p>Create a dedicated branch for your changes. Choose a descriptive name.</p> <pre><code>git checkout -b name-of-your-bugfix-or-feature\n</code></pre>"},{"location":"contributing.html#5-make-your-changes-and-run-checks","title":"5. Make Your Changes and Run Checks","text":"<p>Now, you can modify the code. When you're done, run the project's tests and code formatters to ensure everything is correct.</p> <pre><code># Example: Run tests (if you're using pytest)\npytest\n\n# Example: Format your code (if you're using Black)\nblack .\n</code></pre>"},{"location":"contributing.html#6-commit-your-changes-and-push-to-your-fork","title":"6. Commit Your Changes and Push to Your Fork","text":"<p>Commit your work with a clear message and push the branch to your forked repository on GitHub.</p> <pre><code>git add .\ngit commit -m \"A clear and descriptive commit message\"\ngit push origin name-of-your-bugfix-or-feature\n</code></pre>"},{"location":"contributing.html#7-open-a-pull-request","title":"7. Open a Pull Request","text":"<p>Finally, go to your fork on GitHub. You should see a prompt to \"Compare &amp; pull request\". Click it, review your changes, and submit the pull request to the main <code>easyts</code> repository.</p> <p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include additional tests if appropriate.</li> <li>If the pull request adds functionality, the docs should be updated.</li> <li>The pull request should work for all currently supported operating systems and versions of Python.</li> </ol>"},{"location":"requirements.html","title":"Requirements","text":""},{"location":"requirements.html#core-dependencies","title":"Core Dependencies","text":"<p>The following packages are required to run EasyTest:</p> <ul> <li>numpy~=1.26.4</li> <li>antropy~=0.1.9</li> <li>pycatch22~=0.4.5</li> <li>tsfel~=0.1.9</li> <li>tsfeatures~=0.4.5</li> <li>statsmodels~=0.14.4 </li> <li>ruptures~=1.1.9</li> <li>scikit-learn~=1.6.1</li> </ul>"},{"location":"features/ac.html","title":"Ac","text":""},{"location":"features/ac.html#ac","title":"ac","text":"<p>Computes the autocorrelation of the time-series.</p> <p>Low value: Means the linear relationship between current and past values in the series is very low. High value: Means the linear relationship between current and past values in the sries is very high, and usually indicates one or more trends.</p> <p></p>"},{"location":"features/ac.html#no-parameters","title":"No Parameters","text":""},{"location":"features/ac.html#calculation","title":"Calculation","text":"<ol> <li> <p>Lag 1 Autocovariance: The autocovariance at lag 1 (c1) is calculated.</p> </li> <li> <p>Lag 0 Autocovariance: The autocovariance at lag 0 (c0) is also calculated.</p> </li> <li> <p>Autocorrelation Value: The autocorrelation value that is computed and returned is calculated as: \u03c11 = c0 * c1.</p> </li> </ol>"},{"location":"features/ac.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Demand Forecasting: If daily sales data has a high positive lag-1 autocorrelation, it means high sales one day are likely followed by high sales the next, useful for short-term inventory adjustments.</p> <p>Energy Load Prediction: Electricity load often shows strong positive lag-1 autocorrelation, as load at one hour is very similar to the previous hour, crucial for grid balancing.</p>"},{"location":"features/ac.html#diff_series","title":"diff_series","text":"<p>Computes the autocorrelation value of the differenced series.</p> <p>Low value: Means there is no linear relationship between past and current values in the de-trended series. High value: Means there is a significant linear relationship between past and current values in the de-trended series.</p> <p></p>"},{"location":"features/ac.html#no-parameters_1","title":"No Parameters","text":""},{"location":"features/ac.html#calculation_1","title":"Calculation","text":"<ol> <li> <p>First Differencing: A new time series is created by taking the first differences of the original series, DYt = Yt+1 \u2212 Yt for t=1,...,N\u22121.</p> </li> <li> <p>Autocorrelation of Differenced Series: Then the first 10 autocorrelation coefficients (\u03c11,\u03c12,...,\u03c110) of the differenced series are calculated, using the same method as the ac feature.</p> </li> <li> <p>Sum of Squares: The returned value is calculated as the sum of the squares of these first 10 autocorrelation coefficients.</p> </li> </ol>"},{"location":"features/ac.html#practical-usefulness-examples_1","title":"Practical Usefulness Examples","text":"<p>Financial Returns Analysis: Stock prices are often non-stationary (have a trend/random walk). Analyzing the autocorrelation of their differences (returns) helps identify if there's any remaining predictability after removing the primary random walk component.</p> <p>Process Improvement: If a process output shows a trend, differencing can make it stationary. This feature can then reveal if there are lingering systematic patterns in the rate of change that could be addressed.</p>"},{"location":"features/ac_relevance.html","title":"Autocorrelation Relevance","text":""},{"location":"features/ac_relevance.html#ac_relevance","title":"ac_relevance","text":"<p>Measures the first time lag at which the autocorrelation function drops below 1/e.</p> <p>Low value: Means the series has a more unpredicatble behaviour. High value: Means the series has a more predictable behaviour.</p> <p></p>"},{"location":"features/ac_relevance.html#no-parameters","title":"No Parameters","text":""},{"location":"features/ac_relevance.html#calculation","title":"Calculation","text":"<ol> <li> <p>Autocovariance Function (ACVF): The autocovariance function of the time series Yt is computed for various lags k.</p> </li> <li> <p>First 1/e-Crossing: The feature value is computed and returned as the smallest positive for which ACVF(k) crosses the defined 1/e threshold. </p> </li> </ol>"},{"location":"features/ac_relevance.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Speech Processing: In analyzing a speech signal, the first zero-crossing of the autocovariance can be related to the fundamental frequency (pitch) of voiced segments, helping in speech recognition or speaker identification.</p> <p>Climate Science: For temperature data, this feature might indicate the dominant short-term cyclical component (related to diurnal cycles if data is high frequency, for example).</p>"},{"location":"features/centroid.html","title":"Series Centroid","text":""},{"location":"features/centroid.html#centroid","title":"centroid","text":"<p>Computes the centroid along the time axis.</p> <p>Low value: Means the primary/patterns fluctuations of the series occur slowly. High value: Means the primary patterns/fluctuations of the series occur rapidly, with fast and short-term changes.</p> <p></p> Parameter Type Default Description fs int Mandatory Sampling frequency"},{"location":"features/centroid.html#calculation","title":"Calculation","text":"<ol> <li> <p>Power Spectral Density (PSD): The PSD of the time series is computed, which shows the power of the signal at each frequency f.</p> </li> <li> <p>Centroid Calculation: The spectral centroid C, which is returned, is computed as the power-weighted average of the frequencies. The sum is over all frequency bins k.</p> </li> </ol>"},{"location":"features/centroid.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Audio Analysis: In music information retrieval, the spectral centroid distinguishes between \"bright\" sounds (high centroid, like cymbals) and \"dull\" sounds (low centroid, like a bass drum), aiding in instrument recognition or genre classification.</p> <p>Vibration Analysis: For machine diagnostics, a shift in the spectral centroid of vibration signals can indicate changes in operational speed or the emergence of specific fault frequencies (bearing defects often have characteristic high-frequency components, for example).</p>"},{"location":"features/complexity.html","title":"Series Complexity","text":""},{"location":"features/complexity.html#complexity","title":"complexity","text":"<p>Computes the complexity estimate of the z-normalized time series.</p> <p>Low value: A low/null value means the series is relatively constant over time, with no big changes. High value: A high value means the series has a high complexity, with several big changes.</p> <p></p>"},{"location":"features/complexity.html#no-parameters","title":"No Parameters","text":""},{"location":"features/complexity.html#calculation","title":"Calculation","text":"<ol> <li> <p>Z-Normalization: First, the series is z-normalized.</p> </li> <li> <p>Raw Complexity Estimate: Then, if the length of Z is less than 2, the returned value for complexity is 0. Otherwise, the complexity of the series is computed in the following fashion:</p> <ul> <li>The first differences of the normalized series are computed.</li> <li>The complexity estimate is computed and returned as the square root of the sum of the squares of these differences.</li> </ul> </li> </ol>"},{"location":"features/complexity.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Signal Processing: When comparing different sensor readings that measure the same phenomenon, a much higher complexity in one signal might indicate noise or interference, rather than true signal variation.</p> <p>Machine Condition Monitoring: An increase in the complexity of vibration data from a machine over time could indicate developing faults or wear and tear, as the vibrations become less regular.</p>"},{"location":"features/diff_series.html","title":"Differenced Series","text":""},{"location":"features/diff_series.html#diff_series","title":"diff_series","text":"<p>Computes the autocorrelation value of the differenced series.</p> <p>Low value: Means there is no linear relationship between past and current values in the de-trended series. High value: Means there is a significant linear relationship between past and current values in the de-trended series.</p> <p></p>"},{"location":"features/diff_series.html#no-parameters","title":"No Parameters","text":""},{"location":"features/diff_series.html#calculation","title":"Calculation","text":"<ol> <li> <p>First Differencing: A new time series is created by taking the first differences of the original series, DYt = Yt+1 \u2212 Yt for t=1,...,N\u22121.</p> </li> <li> <p>Autocorrelation of Differenced Series: Then the first 10 autocorrelation coefficients (\u03c11,\u03c12,...,\u03c110) of the differenced series are calculated, using the same method as the ac feature.</p> </li> <li> <p>Sum of Squares: The returned value is calculated as the sum of the squares of these first 10 autocorrelation coefficients.</p> </li> </ol>"},{"location":"features/diff_series.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Financial Returns Analysis: Stock prices are often non-stationary (have a trend/random walk). Analyzing the autocorrelation of their differences (returns) helps identify if there's any remaining predictability after removing the primary random walk component.</p> <p>Process Improvement: If a process output shows a trend, differencing can make it stationary. This feature can then reveal if there are lingering systematic patterns in the rate of change that could be addressed.</p>"},{"location":"features/entropy_pairs.html","title":"Entropy pairs","text":""},{"location":"features/entropy_pairs.html#entropy_pairs","title":"entropy_pairs","text":"<p>Measures entropy based on the 3 quantile bins of the time-series. Low value: Means simpler patterns in the time-series sequence. High value: Means more complex patterns in the time-series sequence.</p> <p></p>"},{"location":"features/entropy_pairs.html#no-parameters","title":"No Parameters","text":""},{"location":"features/entropy_pairs.html#calculation","title":"Calculation","text":"<ol> <li> <p>Symbolization (Coarse Graining): The continuous time series is converted into a discrete symbolic series yt of the same length, which is achieved using a \"quantile\" based method with an alphabet size of 3. Data points are mapped to symbols {1, 2, 3} based on whether they fall into the lower, middle, or upper third of the data's value distribution.</p> </li> <li> <p>Occurrences of Single Symbols Counting: For each symbol s in the alphabet {1, 2, 3}, the indices of all its occurrences in the symbolized series yt are found and their counts are stored.</p> </li> <li> <p>Frequencies of Symbol Pairs (Transitions) Calculation: For every possible pair of symbols (i, j) where i is the current symbol and j is the next symbol (both from {1, 2, 3}), the number of times the sequence \"symbol i followed immediately by symbol j\" appears in yt is counted, and then the normalized frequency for this pair is computed. </p> </li> <li> <p>Conditional Entropies Calculation: For each current symbol i (from 1 to 3), the Shannon entropy of the distribution of the next symbols is computed.</p> </li> <li> <p>Final Sum Calculation: The final value that is computed and returned is the sum of these conditional entropies.</p> </li> </ol>"},{"location":"features/entropy_pairs.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Medical Diagnostics: Analyzing physiological signals (like EEG), specific motif distributions captured by this entropy might differentiate between healthy and pathological states, even if overall signal amplitude or frequency is similar.</p> <p>Anomaly Detection in Sensor Networks: A sudden change in the feature value from the data of a sensor reading could indicate a novel system behavior or a sensor malfunction, suggesting a deviation from its typical complex pattern generation.</p>"},{"location":"features/fluctuation.html","title":"Series Fluctuation","text":""},{"location":"features/fluctuation.html#fluctuation","title":"fluctuation","text":"<p>Measures the proportion of large changes in the time-series. Low value: Means few/none large fluctuations. High value: Means many large fluctuations.</p> <p></p>"},{"location":"features/fluctuation.html#no-parameters","title":"No Parameters","text":""},{"location":"features/fluctuation.html#calculation","title":"Calculation","text":"<ol> <li> <p>Z-Normalization: First, the time series Yt is z-normalized.</p> </li> <li> <p>Successive Differences: Then the absolute differences between consecutive values of the z-normalized series are calculated.</p> </li> <li> <p>Thresholding and Counting: The counting of the number of absolute differences that are greater than a defined threshold (0.04) is computed.</p> </li> <li> <p>Proportion: The final value, which is returned, is the proportion of such differences.</p> </li> </ol>"},{"location":"features/fluctuation.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Financial Market Volatility: In analyzing stock price differences, a high value might indicate a \"jumpy\" market with frequent large price changes over short intervals, signaling higher risk or specific trading conditions.</p> <p>Wearable Health Monitoring: For activity data from a wearable, a higher value could distinguish between smooth, consistent activity and erratic, stop-and-go movements.</p>"},{"location":"features/forecastability.html","title":"Series Forecastability","text":""},{"location":"features/forecastability.html#forecastability","title":"forecastability","text":"<p>Measures the forecastibility of a time-series. Low value: Means there are strong signs of a trend across the time-series. High value: Means the time-series is probably white-noise.</p> <p></p>"},{"location":"features/forecastability.html#parameters-table","title":"Parameters Table","text":"Parameter Type Default Description sf float Mandatory Sampling frequency. method str 'welch' PSD calculation method ('welch' or 'fft'). nperseg int or None None Segment length for welch method. If None, default based on data length normalize bool False Normalize output to [0, 1]"},{"location":"features/forecastability.html#calculation","title":"Calculation","text":"<ol> <li> <p>Power Spectral Density (PSD): The PSD of the time series is computed. This is done using the user chosen model. The Welch's method (the default model) uses these formula: o   The series is divided into (potentially overlapping) segments. o   Each segment is windowed (with a Hann window). o   The Fast Fourier Transform (FFT) is computed for each windowed segment. o   The squared magnitude of the FFT gives the periodogram for that segment. o   The PSD is calculated as the average of these periodograms.</p> </li> <li> <p>Normalization: The PSD is normalized so that it sums to 1, effectively treating it as a probability distribution of power across frequencies.</p> </li> <li> <p>Shannon Entropy: Then the Shannon entropy of this normalized PSD is calculated.</p> </li> <li> <p>Forecastability Value: The computed entropy value is inverted (1/H) and returned.</p> </li> </ol>"},{"location":"features/forecastability.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Inventory Management: For a product with high sales forecastability, a business can maintain lower safety stock. For a product with low forecastability (highly random sales), higher safety stock might be needed to avoid stockouts.</p> <p>Call Center Staffing: If call arrival rates have high forecastability, staffing levels can be optimized more precisely. Low forecastability might require more flexible staffing or overstaffing to handle unpredictable peaks.</p>"},{"location":"features/linear_regression.html","title":"Linear Regression","text":""},{"location":"features/linear_regression.html#linear_regression_slope","title":"linear_regression_slope","text":"<p>Measures the overall linear trend slope. Low value: A negative value means there is a downward trend. High value: A positive value means an upward trend.</p> <p></p>"},{"location":"features/linear_regression.html#no-parameters","title":"No Parameters","text":""},{"location":"features/linear_regression.html#calculation","title":"Calculation","text":"<ol> <li> <p>Linear Regression Fitting: First, the linear regression model yi=\u03b20+\u03b21xi is fitted, yielding predicted values yi.</p> </li> <li> <p>Ordinary Least Squares (OLS): Then, the returned value (slope \u03b21) is estimated by minimizing the sum of squared residuals.</p> </li> </ol>"},{"location":"features/linear_regression.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Resource Depletion: While analyzing the production data of an oil well, the linear regression slope can estimate the average rate of decline in production per month, helping to forecast its remaining lifespan.</p> <p>Agricultural Yields: Farmers can use the slope from regressing crop yield against year to understand the average annual increase or decrease in productivity due to factors like soil changes or farming practices.</p>"},{"location":"features/linear_regression.html#linear_regression_r2","title":"linear_regression_r2","text":"<p>Measures how well a linear trend fits the time-series. Low value: A value close to zero means a linear model explains little variance. High value: A value close to one means a linear model explains much of the variance.</p> <p></p>"},{"location":"features/linear_regression.html#no-parameters_1","title":"No Parameters","text":""},{"location":"features/linear_regression.html#calculation_1","title":"Calculation","text":"<ol> <li> <p>Linear Regression Fitting: First, the linear regression model yi=\u03b20+\u03b21xi is fitted, yielding predicted values y^i.</p> </li> <li> <p>Total Sum of Squares (SST): The total variance in the observed data is then computed as SST.</p> </li> <li> <p>Sum of Squared Residual (SSR): The variance not explained by the model is computed as SSR.</p> </li> <li> <p>R-squared Calculation: The R\u00b2 value, calculated as R\u00b2=1\u2212SST/SSR, is returned.</p> </li> </ol>"},{"location":"features/linear_regression.html#practical-usefulness-examples_1","title":"Practical Usefulness Examples","text":"<p>Software Performance: When analyzing software response time over increasing user load, R\u00b2 indicates how much of the performance degradation is linearly related to the load. A low R\u00b2 might suggest other non-linear factors are at play.</p> <p>Educational Assessment: If tracking student test scores over a semester, R\u00b2 for a linear fit can show how much of the score improvement is explained by a steady learning trend versus other influences.</p>"},{"location":"features/median_crosses.html","title":"Median crosses","text":""},{"location":"features/median_crosses.html#median_crosses","title":"median_crosses","text":"<p>Counts the number of times a time-series crosses the median line. Low value: Means there are few/none oscillations across the time-series. High value: Means there are frequent oscillations across the time-series.</p> <p></p>"},{"location":"features/median_crosses.html#no-parameters","title":"No Parameters","text":""},{"location":"features/median_crosses.html#calculation","title":"Calculation","text":"<ol> <li> <p>Median Value: The median value of the entire time series is calculated.</p> </li> <li> <p>Crosses Counting: Then, for each point Yt and its preceding point Yt\u22121, if (Yt&gt;median and Yt\u22121&lt;median) or (Ytmedian) a crossing is counted. <li> <p>Total Count: The total count of crossings is returned.</p> </li>"},{"location":"features/median_crosses.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Process Control: In manufacturing, if a quality metric frequently crosses its median, it might indicate process instability requiring investigation, even if the average remains acceptable.</p> <p>Environmental Monitoring: Tracking how often a pollutant level crosses its long-term median can highlight periods of increased fluctuation or unusual activity.</p>"},{"location":"features/rec_concentration.html","title":"Records Concentration","text":""},{"location":"features/rec_concentration.html#rec_concentration","title":"rec_concentration","text":"<p>Computes the relative position of the most probable value in relation to the mean.</p> <p>Low value: Means the most frequent values of the series are concentrated significantly below the mean. High value: Means the most frequent values of the series are concentrated significantly above the mean.</p> <p></p>"},{"location":"features/rec_concentration.html#no-parameters","title":"No Parameters","text":""},{"location":"features/rec_concentration.html#calculation","title":"Calculation","text":"<ol> <li> <p>Data Range: The minimum and maximum values of the time series are determined.</p> </li> <li> <p>Binning: The calculated range is divided into 10 equal-width bins.</p> </li> <li> <p>Histogram: The number of data points from the time series that fall into each of the 10 bins are counted.</p> </li> <li> <p>Mode Identification: The bin with the highest count (the modal bin) is identified.</p> </li> <li> <p>Feature Value: The returned value is the midpoint (center value) of this modal bin.</p> </li> </ol>"},{"location":"features/rec_concentration.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Customer Segmentation: While analyzing customer purchase frequency data, this feature might reveal common purchasing patterns (most customers buy 2-3 times a month, for example), helping to segment customers.</p> <p>Sensor Data Validation: If a sensor typically outputs values concentrated in a specific range, a shift in this feature could indicate a calibration issue or a real change in the measured environment.</p>"},{"location":"features/seasonal_strength.html","title":"Seasonal Strength","text":""},{"location":"features/seasonal_strength.html#seasonal_strength","title":"seasonal_strength","text":"<p>Computes the strength of seasonality within the time-series.</p> <p>Low value: A value close to zero means there are few/none indicators of seasonality in the time series. High value: A value close to one means there are strong signs of seasonality in the time-series.</p> <p></p>"},{"location":"features/seasonal_strength.html#parameters-table","title":"Parameters Table","text":"Parameter Type Default Description period int 1 Frequency of the time series (e.g. 12 for monthly) seasonal int 7 Length of the seasonal smoother (must be odd). robust bool False Flag for robust fitting."},{"location":"features/seasonal_strength.html#calculation","title":"Calculation","text":"<ol> <li> <p>STL Decomposition: The time series Yt is decomposed into trend (Tt), seasonal (St), and remainder (Rt) components, using an STL decomposition.</p> </li> <li> <p>Detrended Series: The detrended series is calculated as Yt\u2032=Yt\u2212Tt=St+Rt.</p> </li> <li> <p>Variances Calculation:</p> <ul> <li>The variance of the remainder component is calculated: Var(Rt).</li> <li>The variance of the detrended series is calculated: Var(Yt\u2032).</li> </ul> </li> <li> <p>Seasonal Strength Calculation: The value for seasonal strength is computed as max (0, 1 \u2212 Var(Yt\u2032) * Var(Rt)). This value is capped between 0 and 1 and returned.</p> </li> </ol>"},{"location":"features/seasonal_strength.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Retail Demand Planning: A high seasonal strength for ice cream sales (peaking in summer) allows a company to confidently plan production and marketing efforts around these predictable peaks and troughs.</p> <p>Tourism Industry: Hotels can use the seasonal strength of booking data to optimize pricing, staffing and promotions, anticipating high and low seasons.</p>"},{"location":"features/st_variation.html","title":"Short-Term Variation","text":""},{"location":"features/st_variation.html#st_variation","title":"st_variation","text":"<p>Computes the average of the cube of sucessive time-series differences.</p> <p>Low value: Means the average of the short-term variation across the series is low. High value: Means the average of the short-term variation across the series is high, indicating a frantic behaviour of the data points.</p> <p></p>"},{"location":"features/st_variation.html#no-parameters","title":"No Parameters","text":""},{"location":"features/st_variation.html#calculation","title":"Calculation","text":"<ol> <li> <p>Sucessive Differences: Iterate through the time series from the second point to the penultimate point (t=1 to N\u22121), computing a comparison between each Yt point and its previous Yt-1 point.</p> </li> <li> <p>Final Counting: The number of times Yt &gt; Yt\u22121 is then counted and returned.</p> </li> </ol>"},{"location":"features/st_variation.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Quality Control: In a manufacturing process, if a product dimension shows low short-term variation, it suggests stability. An increase in reversals might indicate an emerging issue.</p> <p>Algorithmic Trading: A high number of local upward movements might suggest short-term momentum that a trading algorithm could try to exploit.</p>"},{"location":"features/trend_changes.html","title":"Trend Changes","text":""},{"location":"features/trend_changes.html#trend_changes","title":"trend_changes","text":"<p>Detects the number of points where the trend changes. Low value: The trend has few/none shifting points, and is constant through time. High value: The trend is constantly shifting, provoking many structural changes.</p> <p></p>"},{"location":"features/trend_changes.html#parameters-table","title":"Parameters Table","text":"Parameter Type Default Description model str 'l2' Cost function model (e.g., 'l1', 'l2', 'rbf') min_size int 2 Minimum number of samples in a segment. jump int 5 Subsample window for considering change points. params dict or None None Additional parameters dictionary for the cost 'model'. custom_cost BaseCost or None None Custom cost function (overrides 'model')."},{"location":"features/trend_changes.html#calculation","title":"Calculation","text":"<ol> <li> <p>Pelt Algorithm (Pruned Exact Linear Time): The minimum cost for segmenting the series up to a point t is calculated. This is done by considering all possible previous points s. For each s, the known minimum cost to segment up to s is used, and the cost of the current segment (from s to t-1) is added alongside a penalty term. The minimum cost is then the smallest value found among all these possible s points. This cost is computed iteratively for every point in the series.</p> </li> <li> <p>Breakpoints Counting: The value returned is the number of detected changepoints (breakpoints) found by backtracking through these optimal choices.</p> </li> </ol>"},{"location":"features/trend_changes.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Economic Analysis: Identifying when an economic indicator like GDP growth rate or unemployment changes its trend can signal shifts in the economic cycle, informing policy decisions.</p> <p>Marketing Campaign Analysis: Detecting trend changes in website traffic or conversion rates after launching a marketing campaign can help assess its impact and identify when its effectiveness starts or wanes.</p>"},{"location":"features/trend_strength.html","title":"Trend Strength","text":""},{"location":"features/trend_strength.html#trend_strength","title":"trend_strength","text":"<p>Computes the strength of a trend within the time-series. Low value: A value close to zero means there are few/none indicators of a trend in the time series. High value: A value close to one means there are strong signs of the series containing a trend.</p> <p></p>"},{"location":"features/trend_strength.html#parameters-table","title":"Parameters Table","text":"Parameter Type Default Description period int 1 Frequency of the time series (e.g. 12 for monthly) seasonal int 7 Length of the seasonal smoother (must be odd). robust bool False Flag for robust fitting."},{"location":"features/trend_strength.html#calculation","title":"Calculation","text":"<ol> <li> <p>STL Decomposition: The time series (Yt) is decomposed into trend (Tt), seasonal (St), and remainder (Rt) components, such that Yt=Tt+St+Rt (for additive decomposition). This is done iteratively:</p> <ul> <li> <p>An initial trend is estimated (using a moving average).</p> </li> <li> <p>The series is detrended (Yt\u2212Tt).</p> </li> <li> <p>The seasonal component is estimated by averaging the detrended series over each seasonal period and then smoothing these seasonal sub-series (using Loess).</p> </li> <li> <p>The seasonal component is removed from the original series to get a seasonally adjusted series (Yt\u2212St).</p> </li> <li> <p>A new trend component Tt is estimated by smoothing the seasonally adjusted series (using Loess).</p> </li> <li> <p>These steps are repeated a few times for robustness.</p> </li> </ul> </li> <li> <p>Deseasonalized Series: The deseasonalized series is calculated as Dt=Yt\u2212St=Tt+Rt.</p> </li> <li> <p>Variances:</p> <ul> <li> <p>The variance of the remainder component is calculated: Var(Rt).</p> </li> <li> <p>The variance of the deseasonalized series is calculated: Var(Dt).</p> </li> </ul> </li> <li> <p>Strength Calculation: Trend strength is computed as: strength=max(0,1\u2212Var(Dt)Var(Rt)). The result is capped between 0 and 1 and returned.</p> </li> </ol>"},{"location":"features/trend_strength.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Retail Sales: A business analyst can use trend strength to assess if an observed increase in monthly sales is a statistically significant upward movement or just part of normal random fluctuations. A strong trend might justify increased inventory orders, while a weak trend might suggest caution.</p> <p>Stock Market Analysis: An investor could use trend strength to determine if a stock price is in a strong, reliable uptrend or downtrend, influencing buy/sell decisions, rather than reacting to short-term volatility.</p>"},{"location":"features/window_fluctuation.html","title":"Window Fluctuation","text":""},{"location":"features/window_fluctuation.html#window_fluctuation","title":"window_fluctuation","text":"<p>Measures the proportion of large changes over short time-windows.</p> <p>Low value: Means the fluctuation of the time-series is more structured and shows few signs of randomness. High value: Means the fluctuation of the time-series shows signs of randomness.</p> <p></p>"},{"location":"features/window_fluctuation.html#no-parameters","title":"No Parameters","text":""},{"location":"features/window_fluctuation.html#calculation","title":"Calculation","text":"<ol> <li> <p>Defining Window Sizes: Approximately 50 window sizes are generated, logarithmically spaced from a minimum defined size up to half the series length. Duplicates are removed and if fewer than 12 unique \u03c4 values remain, the feature returns 0.</p> </li> <li> <p>Cumulative Sum: The series is then transformed into its cumulative sum.</p> </li> <li> <p>Fluctuation Calculation (for each Window Size): For each unique window size the cumulative sum series is divided into non-overlapping segments of length \u03c4. For each segment:</p> <ul> <li>A linear trend is fitted to the segment data points and then is subtracted to get a detrended segment.</li> <li>For the \"rsrangefit\" method: The squared range of this detrended segment is calculated.</li> <li>For the \"dfa\" method: The sum of squares of the values in the detrended segment is calculated. The values for all segments are then aggregated.</li> </ul> </li> <li> <p>Log-Log Analysis and Breakpoint Detection: The logarithms of the window sizes and their corresponding fluctuation values are computed using an algorithm that searches for an optimal breakpoint. This is done by iterating through possible split points. For each split point i:</p> <ul> <li>Fit a linear regression to the first i points.</li> <li>Fit another linear regression to the remaining points.</li> <li>Calculate the sum of squared errors (residuals) for both fits. The total sum of squared errors for this split point i is stored. The split point i that yields the minimum total sum of squared errors is chosen as the optimal breakpoint. A minimum number of points is required for each regression.</li> </ul> </li> <li> <p>Final Computation: The final computed and returned value is the proportion of window sizes that fall into the first linear segment (before the optimal breakpoint).</p> </li> </ol>"},{"location":"features/window_fluctuation.html#practical-usefulness-examples","title":"Practical Usefulness Examples","text":"<p>Financial Time Series: Can help distinguish between periods of persistent trending (Hurst exponent &gt; 0.5) and anti-persistent, mean-reverting behavior (Hurst &lt; 0.5) in asset prices, informing trading strategies.</p> <p>Geophysical Data Analysis: In analyzing earthquake data or river flow levels, this feature can characterize the long-range dependence or memory effects, helping to understand the underlying physical processes.</p>"},{"location":"features/noise/ac.html","title":"Ac","text":""},{"location":"features/noise/ac.html#ac","title":"ac","text":"<p>Computes the autocorrelation of the time-series.</p> <p>Low value: Means the linear relationship between current and past values in the series is very low. High value: Means the linear relationship between current and past values in the sries is very high, and usually indicates one or more trends.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/ac.html#diff_series","title":"diff_series","text":"<p>Computes the autocorrelation value of the differenced series.</p> <p>Low value: Means there is no linear relationship between past and current values in the de-trended series. High value: Means there is a significant linear relationship between past and current values in the de-trended series.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/ac_relevance.html","title":"Ac relevance","text":""},{"location":"features/noise/ac_relevance.html#ac_relevance","title":"ac_relevance","text":"<p>Measures the first time lag at which the autocorrelation function drops below 1/e.</p> <p>Low value: Means the series has a more unpredicatble behaviour. High value: Means the series has a more predictable behaviour.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/centroid.html","title":"Centroid","text":""},{"location":"features/noise/centroid.html#centroid","title":"centroid","text":"<p>Computes the centroid along the time axis.</p> <p>Low value: Means the primary/patterns fluctuations of the series occur slowly. High value: Means the primary patterns/fluctuations of the series occur rapidly, with fast and short-term changes.</p> <p></p> Parameters Table Parameter Type Default Description fs int Mandatory Sampling frequency"},{"location":"features/noise/complexity.html","title":"Complexity","text":""},{"location":"features/noise/complexity.html#rec_concentration","title":"rec_concentration","text":"<p>Computes the relative position of the most probable value in relation to the mean.</p> <p>Low value: Means the most frequent values of the series are concentrated significantly below the mean. High value: Means the most frequent values of the series are concentrated significantly above the mean.</p> <p>No parameters</p>"},{"location":"features/noise/diff_series.html","title":"Diff series","text":""},{"location":"features/noise/diff_series.html#diff_series","title":"diff_series","text":"<p>Computes the autocorrelation value of the differenced series.</p> <p>Low value: Means there is no linear relationship between past and current values in the de-trended series. High value: Means there is a significant linear relationship between past and current values in the de-trended series.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/entropy_pairs.html","title":"Entropy pairs","text":""},{"location":"features/noise/entropy_pairs.html#entropy_pairs","title":"entropy_pairs","text":"<p>Measures entropy based on the 3 quantile bins of the time-series. Low value: Means simpler patterns in the time-series sequence. High value: Means more complex patterns in the time-series sequence.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/fluctuation.html","title":"Fluctuation","text":""},{"location":"features/noise/fluctuation.html#fluctuation","title":"fluctuation","text":"<p>Measures the proportion of large changes in the time-series. Low value: Means few/none large fluctuations. High value: Means many large fluctuations.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/forecastability.html","title":"Forecastability","text":""},{"location":"features/noise/forecastability.html#forecastability","title":"forecastability","text":"<p>Measures the forecastibility of a time-series. Low value: Means there are strong signs of a trend across the time-series. High value: Means the time-series is probably white-noise.</p> <p></p> Parameters Table Parameter Type Default Description sf float Mandatory Sampling frequency. method str welch PSD calculation method ('welch' or 'fft'). nperseg int or None None Segment length for welch method. If None, default based on data length normalize bool False Normalize output to [0, 1]"},{"location":"features/noise/seasonal_strength.html","title":"Seasonal strength","text":""},{"location":"features/noise/seasonal_strength.html#seasonal_strength","title":"seasonal_strength","text":"<p>Computes the strength of seasonality within the time-series.</p> <p>Low value: A value close to zero means there are few/none indicators of seasonality in the time series. High value: A value close to one means there are strong signs of seasonality in the time-series.</p> <p></p> Parameters Table Parameter Type Default Description period int '1' Frequency of the time series (e.g. 12 for monthly) seasonal int 7 Length of the seasonal smoother (must be odd). robust bool False Flag for robust fitting."},{"location":"features/noise/st_variation.html","title":"St variation","text":""},{"location":"features/noise/st_variation.html#st_variation","title":"st_variation","text":"<p>Computes the average of the cube of sucessive time-series differences.</p> <p>Low value: Means the average of the short-term variation across the series is low. High value: Means the average of the short-term variation across the series is high, indicating a frantic behaviour of the data points.</p> <p></p> <p>No parameters</p>"},{"location":"features/noise/window_fluctuation.html","title":"Window fluctuation","text":""},{"location":"features/noise/window_fluctuation.html#window_fluctuation","title":"window_fluctuation","text":"<p>Measures the proportion of large changes over short time-windows.</p> <p>Low value: Means the fluctuation of the time-series is more structured and shows few signs of randomness. High value: Means the fluctuation of the time-series shows signs of randomness.</p> <p></p> <p>No parameters</p>"},{"location":"features/trend/linear_regression.html","title":"Linear regression","text":""},{"location":"features/trend/linear_regression.html#linear_regression_slope","title":"linear_regression_slope","text":"<p>Measures the overall linear trend slope. Low value: A negative value means there is a downward trend. High value: A positive value means an upward trend.</p> <p></p> <p>No parameters</p>"},{"location":"features/trend/linear_regression.html#linear_regression_r2","title":"linear_regression_r2","text":"<p>Measures how well a linear trend fits the time-series. Low value: A value close to zero means a linear model explains little variance. High value: A value close to one means a linear model explains much of the variance.</p> <p></p> <p>No parameters</p>"},{"location":"features/trend/median_crosses.html","title":"Median crosses","text":""},{"location":"features/trend/median_crosses.html#median_crosses","title":"median_crosses","text":"<p>Counts the number of times a time-series crosses the median line. Low value: Means there are few/none oscillations across the time-series. High value: Means there are frequent oscillations across the time-series.</p> <p></p> <p>No parameters</p>"},{"location":"features/trend/trend_changes.html","title":"Trend changes","text":""},{"location":"features/trend/trend_changes.html#trend_changes","title":"trend_changes","text":"<p>Detects the number of points where the trend changes. Low value: The trend has few/none shifting points, and is constant through time. High value: The trend is constantly shifting, provoking many structural changes.</p> <p></p> Parameters Table Parameter Type Default Description model str 'l2' Cost function model (e.g., 'l1', 'l2', 'rbf') min_size int 2 Minimum number of samples in a segment. jump int 5 Subsample window for considering change points. params dict or None None Additional parameters dictionary for the cost 'model'. custom_cost BaseCost or None None Custom cost function (overrides 'model')."},{"location":"features/trend/trend_strength.html","title":"Trend strength","text":""},{"location":"features/trend/trend_strength.html#trend_strength","title":"trend_strength","text":"<p>Computes the strength of a trend within the time-series. Low value: A value close to zero means there are few/none indicators of a trend in the time series. High value: A value close to one means there are strong signs of the series containing a trend.</p> <p></p> Parameters Table Parameter Type Default Description period int '1' Frequency of the time series (e.g. 12 for monthly) seasonal int 7 Length of the seasonal smoother (must be odd). robust bool False Flag for robust fitting."}]}